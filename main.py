import asyncio
import aiohttp
import re
import os
import json
from datetime import datetime

# ================= é…ç½®åŒº =================
# å»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼Œæˆ–è€…ç›´æ¥åœ¨æ­¤å¤„ä¿®æ”¹
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "ä½ çš„_GITHUB_TOKEN")
SEARCH_QUERY = '"api/v1/client/subscribe?token="'
MASTER_FILE = "all_link.txt"
CONCURRENT_LIMIT = 25  # å¹¶å‘ä¸‹è½½æ•°

# Telegram é…ç½®
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN", "ä½ çš„_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID", "ä½ çš„_CHAT_ID")
# ==========================================

HEADERS = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

def get_existing_links():
    """è¯»å–æœ¬åœ°å·²å­˜åœ¨çš„é“¾æ¥ï¼Œç¡®ä¿å»é‡"""
    if not os.path.exists(MASTER_FILE): 
        return set()
    with open(MASTER_FILE, "r", encoding="utf-8") as f:
        # strip() ç§»é™¤æ¢è¡Œç¬¦å’Œé¦–å°¾ç©ºæ ¼
        return set(line.strip() for line in f if line.strip())

def build_raw_url(item):
    """å°† GitHub HTML URL è½¬æ¢ä¸º Raw URL"""
    html_url = item.get('html_url', '')
    if not html_url: return None
    return html_url.replace("github.com", "raw.githubusercontent.com").replace("/blob/", "/")

async def send_telegram_msg(session, new_count, sample_links):
    """å‘é€æ–‡å­—æ¶ˆæ¯"""
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"
    msg_text = (
        f"ğŸš€ *å‘ç°å°‘é‡æ–°è®¢é˜… ({new_count}æ¡)*\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    )
    # ç¡®ä¿æ’åºåè¾“å‡ºï¼Œæ•´é½ç¾è§‚
    for i, link in enumerate(sorted(sample_links), 1):
        msg_text += f"{i}. `{link}`\n"

    payload = {
        "chat_id": TG_CHAT_ID, 
        "text": msg_text, 
        "parse_mode": "Markdown", 
        "disable_web_page_preview": True
    }
    async with session.post(url, json=payload) as resp:
        return await resp.json()

async def send_telegram_file(session, new_count, file_path):
    """å‘é€æ–‡ä»¶"""
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendDocument"
    caption = (
        f"ğŸ“‚ *æ–°è®¢é˜…æ–‡ä»¶æ¨é€*\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ†• æœ¬æ¬¡æ–°å¢: `{new_count}` æ¡\n"
        f"ğŸ“… æ—¶é—´: `{datetime.now().strftime('%Y-%m-%d %H:%M')}`"
    )
    
    data = aiohttp.FormData()
    data.add_field('chat_id', TG_CHAT_ID)
    data.add_field('caption', caption)
    data.add_field('parse_mode', 'Markdown')
    data.add_field('document', open(file_path, 'rb'), filename=os.path.basename(file_path))
    
    try:
        async with session.post(url, data=data) as resp:
            if resp.status == 200:
                print("Telegram æ–‡ä»¶æ¨é€æˆåŠŸï¼")
            else:
                print(f"æ–‡ä»¶æ¨é€å¤±è´¥: {resp.status}")
    except Exception as e:
        print(f"æ–‡ä»¶æ¨é€å¼‚å¸¸: {e}")

async def fetch_content_and_extract(session, raw_url, sem):
    """ä¸‹è½½æ–‡ä»¶å†…å®¹å¹¶ä½¿ç”¨é‡æ„åçš„æ­£åˆ™æå–é“¾æ¥"""
    # æ”¹è¿›åçš„æ­£åˆ™ï¼šæ’é™¤æ‰å¸¸è§çš„ HTML/JSON é—­åˆç¬¦å·ï¼Œæ”¯æŒ token ä¸­çš„ - å’Œ _
    link_pattern = re.compile(r'https?://[^\s"\'\)\<\>\[\]]+?api/v1/client/subscribe\?token=[a-zA-Z0-9\-_]+')
    
    async with sem:
        try:
            async with session.get(raw_url, timeout=15) as resp:
                if resp.status == 200:
                    text = await resp.text(errors='ignore')
                    extracted = link_pattern.findall(text)
                    # æ¸…æ´—æå–åˆ°çš„ç»“æœï¼Œç¡®ä¿æ— ç©ºæ ¼
                    return {link.strip() for link in extracted if link.strip()}
        except: 
            pass
    return set()

async def run_crawler():
    old_links = get_existing_links()
    all_current_links = set()
    sem = asyncio.Semaphore(CONCURRENT_LIMIT)

    async with aiohttp.ClientSession(headers=HEADERS) as session:
        print(f"[{datetime.now()}] é˜¶æ®µ 1: æœç´¢ GitHub æ–‡ä»¶åˆ—è¡¨...")
        file_items = []
        page = 1
        while page <= 10:
            search_url = f"https://api.github.com/search/code?q={SEARCH_QUERY}&sort=indexed&order=desc&per_page=100&page={page}"
            async with session.get(search_url) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    items = data.get('items', [])
                    if not items: break
                    file_items.extend(items)
                    print(f"  - ç¬¬ {page} é¡µè·å–æˆåŠŸ ({len(file_items)} ä¸ªæ–‡ä»¶)")
                    page += 1
                    if page <= 10: await asyncio.sleep(8) # é¿å¼€ GitHub é¢‘ç‡é™åˆ¶
                elif resp.status == 403:
                    retry_after = int(resp.headers.get("Retry-After", 60))
                    print(f"  ! è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œä¼‘çœ  {retry_after} ç§’...")
                    await asyncio.sleep(retry_after)
                else: 
                    break

        print(f"[{datetime.now()}] é˜¶æ®µ 2: å¼‚æ­¥æå–é“¾æ¥ä¸­...")
        tasks = [fetch_content_and_extract(session, build_raw_url(item), sem) for item in file_items if build_raw_url(item)]
        results = await asyncio.gather(*tasks)
        for r in results: 
            all_current_links.update(r)

        # é˜¶æ®µ 3: å¢é‡å¤„ç†ä¸æ ¼å¼åŒ–ä¿å­˜
        new_links = all_current_links - old_links
        if new_links:
            sorted_new_links = sorted(list(new_links))
            new_count = len(sorted_new_links)
            
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            time_filename = f"new_links_{timestamp}.txt"
            
            # 1. ä¿å­˜æœ¬æ¬¡æ–°å¢é“¾æ¥åˆ°ç‹¬ç«‹æ–‡ä»¶ (æ¯è¡Œä¸€ä¸ª)
            with open(time_filename, "w", encoding="utf-8") as f:
                f.write("\n".join(sorted_new_links) + "\n")
            
            # 2. è¿½åŠ åˆ°æ€»è¡¨ MASTER_FILE (ç¡®ä¿æ¯è¡Œä¸€ä¸ªï¼Œå¤„ç†æœ«å°¾æ¢è¡Œ)
            with open(MASTER_FILE, "a", encoding="utf-8") as f:
                for link in sorted_new_links:
                    f.write(link + "\n")
            
            print(f"[{datetime.now()}] å‘ç° {new_count} æ¡æ–°è®¢é˜…ï¼")

            # 3. åˆ†çº§æ¨é€
            if new_count < 10:
                await send_telegram_msg(session, new_count, sorted_new_links)
            else:
                await send_telegram_file(session, new_count, time_filename)
        else:
            print(f"[{datetime.now()}] æœªå‘ç°æ–°é“¾æ¥ã€‚")

if __name__ == "__main__":
    asyncio.run(run_crawler())